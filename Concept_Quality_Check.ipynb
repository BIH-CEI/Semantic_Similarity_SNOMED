{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oBDS SNOMED Concept Quality Check\n",
    "\n",
    "This notebook performs quality validation on the unique SNOMED concepts extracted from the oBDS mapping project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Compare Concept Lists from Different Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unique concepts from the notebook\n",
    "print(\"Loading unique concepts from Jupyter notebook...\")\n",
    "try:\n",
    "    # This would need to be extracted from the notebook or provided as a list\n",
    "    notebook_concepts = ['439401001', '900000000000465024', '371480007', '432213005', \n",
    "                        '373793006', '58147004', '165197003', '363680008', '423827005',\n",
    "                        '363679005', '16310003', '76145000', '86481000', '29240004',\n",
    "                        '259672007', '702666009', '714797009', '261665006', '7771000',\n",
    "                        '24028007', '51440002', '255561001', '396360001', '275904003',\n",
    "                        '439272007', '373372005', '263933003', '384812005', '263843001',\n",
    "                        '263918006', '911753521000003968', '1155705000', '1155708003',\n",
    "                        '1286893008', '1155707008', '1268929003', '385432009', '444025001',\n",
    "                        '443527007', '444411008', '1264491009', '404684003', '278201002',\n",
    "                        '410672004', '734841007', '263486008', '445200009', '262061000',\n",
    "                        '386053000', '371497001', '385421009', '39607008', '272673000'] # truncated for space\n",
    "    \n",
    "    print(f\"Loaded {len(notebook_concepts)} concepts from notebook\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading notebook concepts: {e}\")\n",
    "    notebook_concepts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load concepts from R script (hardcoded list)\n",
    "print(\"Loading unique concepts from R script...\")\n",
    "try:\n",
    "    r_script_path = \"rawData/oBDS/Krippendorff Alpha/Kripp_Taxonomy.R\"\n",
    "    with open(r_script_path, 'r', encoding='utf-8') as f:\n",
    "        r_content = f.read()\n",
    "    \n",
    "    # Extract the uniqueIDs list from R script\n",
    "    pattern = r'uniqueIDs <- c\\((.*?)\\)'\n",
    "    match = re.search(pattern, r_content, re.DOTALL)\n",
    "    if match:\n",
    "        ids_string = match.group(1)\n",
    "        # Parse the quoted strings\n",
    "        r_concepts = re.findall(r'\"([^\"]+)\"', ids_string)\n",
    "        print(f\"Loaded {len(r_concepts)} concepts from R script\")\n",
    "    else:\n",
    "        print(\"Could not find uniqueIDs in R script\")\n",
    "        r_concepts = []\n",
    "except Exception as e:\n",
    "    print(f\"Error loading R script concepts: {e}\")\n",
    "    r_concepts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load concepts from distance matrix\n",
    "print(\"Loading concepts from distance matrix...\")\n",
    "try:\n",
    "    distance_matrix_path = \"rawData/oBDS/Krippendorff Alpha/oBDS_distance_matrix.csv\"\n",
    "    df_distance = pd.read_csv(distance_matrix_path, index_col=0, nrows=5)  # Just load header and few rows\n",
    "    matrix_concepts = list(df_distance.columns)\n",
    "    print(f\"Loaded {len(matrix_concepts)} concepts from distance matrix\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading distance matrix concepts: {e}\")\n",
    "    matrix_concepts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load concepts from main Excel file (sample - you may need to adjust sheet names)\n",
    "print(\"Loading concepts from main Excel file...\")\n",
    "try:\n",
    "    excel_path = \"rawData/oBDS/oBDS_Module_alle_neu.xlsx\"\n",
    "    excel_file = pd.ExcelFile(excel_path)\n",
    "    \n",
    "    # Get all unique SNOMED codes from all sheets and mapper columns\n",
    "    all_excel_concepts = set()\n",
    "    \n",
    "    for sheet_name in excel_file.sheet_names[:3]:  # Check first 3 sheets as sample\n",
    "        try:\n",
    "            df_sheet = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "            \n",
    "            # Look for columns that might contain SNOMED codes (typically named with SCTID)\n",
    "            sctid_columns = [col for col in df_sheet.columns if 'SCTID' in str(col) or 'sct' in str(col).lower()]\n",
    "            \n",
    "            for col in sctid_columns:\n",
    "                concepts = df_sheet[col].dropna().astype(str).tolist()\n",
    "                # Filter for valid SNOMED format (6-18 digits)\n",
    "                valid_concepts = [c for c in concepts if re.match(r'\\d{6,18}$', c)]\n",
    "                all_excel_concepts.update(valid_concepts)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sheet {sheet_name}: {e}\")\n",
    "    \n",
    "    excel_concepts = list(all_excel_concepts)\n",
    "    print(f\"Loaded {len(excel_concepts)} concepts from Excel file (sample from first 3 sheets)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading Excel concepts: {e}\")\n",
    "    excel_concepts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Concept Format Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_snomed_format(concept_id):\n",
    "    \"\"\"\n",
    "    Validate SNOMED CT concept ID format.\n",
    "    Valid SNOMED IDs are 6-18 digits long and follow specific rules.\n",
    "    \"\"\"\n",
    "    if not isinstance(concept_id, str):\n",
    "        return False, \"Not a string\"\n",
    "    \n",
    "    # Remove whitespace\n",
    "    concept_id = concept_id.strip()\n",
    "    \n",
    "    # Check if it's all digits\n",
    "    if not concept_id.isdigit():\n",
    "        return False, \"Contains non-digit characters\"\n",
    "    \n",
    "    # Check length (SNOMED IDs are typically 6-18 digits)\n",
    "    if len(concept_id) < 6:\n",
    "        return False, \"Too short (< 6 digits)\"\n",
    "    if len(concept_id) > 18:\n",
    "        return False, \"Too long (> 18 digits)\"\n",
    "    \n",
    "    # Check for leading zeros (unusual in SNOMED)\n",
    "    if concept_id.startswith('0') and len(concept_id) > 1:\n",
    "        return False, \"Has leading zeros\"\n",
    "    \n",
    "    return True, \"Valid format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all concept sources for comprehensive analysis\n",
    "all_sources = {\n",
    "    'R_Script': r_concepts,\n",
    "    'Distance_Matrix': matrix_concepts,\n",
    "    'Excel_Sample': excel_concepts\n",
    "}\n",
    "\n",
    "print(\"=== CONCEPT SOURCE COMPARISON ===\")\n",
    "for source_name, concepts in all_sources.items():\n",
    "    print(f\"{source_name}: {len(concepts)} concepts\")\n",
    "\n",
    "# Use R script concepts as the primary list for detailed validation\n",
    "primary_concepts = r_concepts if r_concepts else matrix_concepts\n",
    "print(f\"\\nUsing {len(primary_concepts)} concepts from primary source for detailed validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate all concepts in primary list\n",
    "print(\"=== CONCEPT FORMAT VALIDATION ===\")\n",
    "\n",
    "validation_results = []\n",
    "for concept in primary_concepts:\n",
    "    is_valid, reason = validate_snomed_format(concept)\n",
    "    validation_results.append({\n",
    "        'concept_id': concept,\n",
    "        'is_valid': is_valid,\n",
    "        'issue': reason if not is_valid else None,\n",
    "        'length': len(str(concept))\n",
    "    })\n",
    "\n",
    "df_validation = pd.DataFrame(validation_results)\n",
    "\n",
    "# Summary statistics\n",
    "total_concepts = len(df_validation)\n",
    "valid_concepts = df_validation['is_valid'].sum()\n",
    "invalid_concepts = total_concepts - valid_concepts\n",
    "\n",
    "print(f\"Total concepts: {total_concepts}\")\n",
    "print(f\"Valid format: {valid_concepts} ({valid_concepts/total_concepts*100:.1f}%)\")\n",
    "print(f\"Invalid format: {invalid_concepts} ({invalid_concepts/total_concepts*100:.1f}%)\")\n",
    "\n",
    "if invalid_concepts > 0:\n",
    "    print(\"\\nInvalid concepts:\")\n",
    "    invalid_df = df_validation[~df_validation['is_valid']]\n",
    "    print(invalid_df[['concept_id', 'issue', 'length']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Duplicate Detection and Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DUPLICATE DETECTION ===\")\n",
    "\n",
    "# Check for exact duplicates\n",
    "concept_counts = Counter(primary_concepts)\n",
    "duplicates = {concept: count for concept, count in concept_counts.items() if count > 1}\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"Found {len(duplicates)} duplicate concepts:\")\n",
    "    for concept, count in duplicates.items():\n",
    "        print(f\"  {concept}: appears {count} times\")\n",
    "else:\n",
    "    print(\"No exact duplicates found\")\n",
    "\n",
    "# Check for near-duplicates (concepts that differ only by leading/trailing whitespace)\n",
    "cleaned_concepts = [str(c).strip() for c in primary_concepts]\n",
    "original_vs_cleaned = list(zip(primary_concepts, cleaned_concepts))\n",
    "whitespace_issues = [(orig, clean) for orig, clean in original_vs_cleaned if orig != clean]\n",
    "\n",
    "if whitespace_issues:\n",
    "    print(f\"\\nFound {len(whitespace_issues)} concepts with whitespace issues:\")\n",
    "    for orig, clean in whitespace_issues[:10]:  # Show first 10\n",
    "        print(f\"  '{orig}' -> '{clean}'\")\nelse:\n",
    "    print(\"\\nNo whitespace issues found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Special SNOMED Codes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SPECIAL SNOMED CODES ANALYSIS ===\")\n",
    "\n",
    "# Check for special SNOMED codes\n",
    "special_codes = {\n",
    "    '900000000000465024': 'SNOMED CT Namespace',\n",
    "    '900000000000519040': 'SNOMED CT Core',\n",
    "    '138875005': 'SNOMED CT Concept (root)',\n",
    "    '900000000000441003': 'SNOMED CT URI',\n",
    "}\n",
    "\n",
    "found_special = []\n",
    "for concept in primary_concepts:\n",
    "    if concept in special_codes:\n",
    "        found_special.append((concept, special_codes[concept]))\n",
    "\n",
    "if found_special:\n",
    "    print(\"Found special SNOMED codes:\")\n",
    "    for concept, description in found_special:\n",
    "        print(f\"  {concept}: {description}\")\nelse:\n",
    "    print(\"No known special codes found\")\n",
    "\n",
    "# Check for extension concepts (non-international)\n",
    "# Extension concepts often have specific patterns in their IDs\n",
    "extension_concepts = []\n",
    "for concept in primary_concepts:\n",
    "    if len(concept) > 10:  # Extensions are often longer\n",
    "        # Check for common extension patterns\n",
    "        if '1000' in concept[-8:]:  # Common extension pattern\n",
    "            extension_concepts.append(concept)\n",
    "\n",
    "print(f\"\\nPotential extension concepts: {len(extension_concepts)}\")\nif extension_concepts:\n",
    "    print(\"Sample extension concepts:\")\n",
    "    for concept in extension_concepts[:10]:\n",
    "        print(f\"  {concept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Length Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CONCEPT ID LENGTH DISTRIBUTION ===\")\n",
    "\n",
    "# Analyze length distribution\n",
    "lengths = [len(str(concept)) for concept in primary_concepts]\n",
    "length_counts = Counter(lengths)\n",
    "\n",
    "print(\"Length distribution:\")\n",
    "for length in sorted(length_counts.keys()):\n",
    "    count = length_counts[length]\n",
    "    percentage = count / len(primary_concepts) * 100\n",
    "    print(f\"  {length} digits: {count} concepts ({percentage:.1f}%)\")\n",
    "\n",
    "# Statistical summary\n",
    "lengths_array = np.array(lengths)\n",
    "print(f\"\\nLength statistics:\")\n",
    "print(f\"  Mean: {lengths_array.mean():.1f}\")\n",
    "print(f\"  Median: {np.median(lengths_array):.1f}\")\n",
    "print(f\"  Min: {lengths_array.min()}\")\n",
    "print(f\"  Max: {lengths_array.max()}\")\n",
    "print(f\"  Std: {lengths_array.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Source Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CROSS-SOURCE CONSISTENCY ===\")\n",
    "\n",
    "# Compare concepts across different sources\n",
    "if len(all_sources) > 1:\n",
    "    source_names = list(all_sources.keys())\n",
    "    \n",
    "    for i, source1 in enumerate(source_names):\n",
    "        for source2 in source_names[i+1:]:\n",
    "            set1 = set(all_sources[source1])\n",
    "            set2 = set(all_sources[source2])\n",
    "            \n",
    "            intersection = set1 & set2\n",
    "            union = set1 | set2\n",
    "            only_in_1 = set1 - set2\n",
    "            only_in_2 = set2 - set1\n",
    "            \n",
    "            jaccard = len(intersection) / len(union) if union else 0\n",
    "            \n",
    "            print(f\"\\n{source1} vs {source2}:\")\n",
    "            print(f\"  Common concepts: {len(intersection)}\")\n",
    "            print(f\"  Only in {source1}: {len(only_in_1)}\")\n",
    "            print(f\"  Only in {source2}: {len(only_in_2)}\")\n",
    "            print(f\"  Jaccard similarity: {jaccard:.3f}\")\n",
    "            \n",
    "            # Show sample differences\n",
    "            if only_in_1 and len(only_in_1) <= 10:\n",
    "                print(f\"  Concepts only in {source1}: {sorted(list(only_in_1))}\")\n",
    "            if only_in_2 and len(only_in_2) <= 10:\n",
    "                print(f\"  Concepts only in {source2}: {sorted(list(only_in_2))}\")\nelse:\n",
    "    print(\"Only one source available - cannot compare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations and Action Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== QUALITY CHECK SUMMARY AND RECOMMENDATIONS ===\")\n",
    "\n",
    "issues_found = []\n",
    "recommendations = []\n",
    "\n",
    "# Check validation results\n",
    "if 'df_validation' in locals():\n",
    "    invalid_count = (~df_validation['is_valid']).sum()\n",
    "    if invalid_count > 0:\n",
    "        issues_found.append(f\"{invalid_count} concepts with invalid format\")\n",
    "        recommendations.append(\"Review and correct invalid concept IDs\")\n",
    "\n",
    "# Check duplicates\n",
    "if duplicates:\n",
    "    issues_found.append(f\"{len(duplicates)} duplicate concepts found\")\n",
    "    recommendations.append(\"Remove duplicate concepts from analysis\")\n",
    "\n",
    "# Check whitespace issues\n",
    "if 'whitespace_issues' in locals() and whitespace_issues:\n",
    "    issues_found.append(f\"{len(whitespace_issues)} concepts with whitespace issues\")\n",
    "    recommendations.append(\"Clean whitespace from concept IDs\")\n",
    "\n",
    "# Check extension concepts\n",
    "if 'extension_concepts' in locals() and extension_concepts:\n",
    "    extension_pct = len(extension_concepts) / len(primary_concepts) * 100\n",
    "    if extension_pct > 10:\n",
    "        issues_found.append(f\"{len(extension_concepts)} potential extension concepts ({extension_pct:.1f}%)\")\n",
    "        recommendations.append(\"Verify extension concepts are intended and available in target SNOMED release\")\n",
    "\n",
    "print(\"ISSUES FOUND:\")\n",
    "if issues_found:\n",
    "    for i, issue in enumerate(issues_found, 1):\n",
    "        print(f\"{i}. {issue}\")\nelse:\n",
    "    print(\"No major issues detected!\")\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS:\")\n",
    "if recommendations:\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\nelse:\n",
    "    print(\"No specific recommendations - concept list appears clean!\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"1. Validate concepts against actual SNOMED CT release files\")\n",
    "print(\"2. Check concept status (active/inactive)\")\n",
    "print(\"3. Verify concepts exist in the target SNOMED edition/version\")\n",
    "print(\"4. Create cleaned concept list for final analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Clean Concept List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cleaned concept list\n",
    "if 'df_validation' in locals():\n",
    "    clean_concepts = df_validation[df_validation['is_valid']]['concept_id'].tolist()\n",
    "else:\n",
    "    clean_concepts = [str(c).strip() for c in primary_concepts if validate_snomed_format(str(c).strip())[0]]\n",
    "\n",
    "# Remove duplicates\n",
    "clean_concepts = list(set(clean_concepts))\n",
    "clean_concepts.sort()\n",
    "\n",
    "print(f\"Clean concept list: {len(clean_concepts)} unique valid concepts\")\n",
    "\n",
    "# Save to file\n",
    "output_file = \"clean_snomed_concepts.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for concept in clean_concepts:\n",
    "        f.write(f\"{concept}\\n\")\n",
    "\n",
    "print(f\"Clean concept list saved to: {output_file}\")\n",
    "\n",
    "# Also save as CSV with additional info\n",
    "clean_df = pd.DataFrame({\n",
    "    'concept_id': clean_concepts,\n",
    "    'length': [len(c) for c in clean_concepts],\n",
    "    'is_extension': [len(c) > 10 and '1000' in c[-8:] for c in clean_concepts]\n",
    "})\n",
    "\n",
    "clean_df.to_csv(\"clean_snomed_concepts.csv\", index=False)\n",
    "print(f\"Clean concept details saved to: clean_snomed_concepts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}